{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cs484_project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1maJgn9Dp7KSMr0Vla80dQFTvxXxRJOLj",
      "authorship_tag": "ABX9TyNK+kHDJEXOdRPpfxhhc3If",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArjunNarayan2066/CS484_project/blob/fixed_training_loop/cs484_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 977
        },
        "id": "JnRlwbQ9z4kL",
        "outputId": "e8f7bc39-8bac-47b3-f0cd-7fee108be135"
      },
      "source": [
        "# Install dependencies\r\n",
        "! nvcc --version\r\n",
        "\r\n",
        "! pip install torch==1.7.1+cu101 torchvision==0.8.2+cu101 -f https://download.pytorch.org/whl/torch_stable.html\r\n",
        "! pip install tensorboardX==1.4\r\n",
        "! pip install opencv-python==3.3.1.11\r\n",
        "\r\n",
        "# Clone repo\r\n",
        "! git clone https://github.com/ArjunNarayan2066/monodepth2.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.7.1+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torch-1.7.1%2Bcu101-cp36-cp36m-linux_x86_64.whl (735.4MB)\n",
            "\u001b[K     |████████████████████████████████| 735.4MB 24kB/s \n",
            "\u001b[?25hCollecting torchvision==0.8.2+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.8.2%2Bcu101-cp36-cp36m-linux_x86_64.whl (12.8MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8MB 242kB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from torch==1.7.1+cu101) (0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch==1.7.1+cu101) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.7.1+cu101) (1.19.4)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.8.2+cu101) (7.0.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.7.0+cu101\n",
            "    Uninstalling torch-1.7.0+cu101:\n",
            "      Successfully uninstalled torch-1.7.0+cu101\n",
            "  Found existing installation: torchvision 0.8.1+cu101\n",
            "    Uninstalling torchvision-0.8.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.8.1+cu101\n",
            "Successfully installed torch-1.7.1+cu101 torchvision-0.8.2+cu101\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorboardX==1.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/d2/e08fe62f3554fbba081e80f6b23128df53b2f74ed4dcde73ec4a84dc53fb/tensorboardX-1.4-py2.py3-none-any.whl (67kB)\n",
            "\r\u001b[K     |████▉                           | 10kB 22.4MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 20kB 29.3MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 30kB 15.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 40kB 11.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 51kB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 61kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 5.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX==1.4) (1.19.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX==1.4) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX==1.4) (3.12.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.2.0->tensorboardX==1.4) (50.3.2)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-1.4\n",
            "Collecting opencv-python==3.3.1.11\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5d/2e/94488235b5708390dc03c425b7bf47babad73283297d9989c3abef45f255/opencv_python-3.3.1.11-cp36-cp36m-manylinux1_x86_64.whl (24.7MB)\n",
            "\u001b[K     |████████████████████████████████| 24.7MB 129kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python==3.3.1.11) (1.19.4)\n",
            "\u001b[31mERROR: dopamine-rl 1.0.5 has requirement opencv-python>=3.4.1.15, but you'll have opencv-python 3.3.1.11 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: opencv-python\n",
            "  Found existing installation: opencv-python 4.1.2.30\n",
            "    Uninstalling opencv-python-4.1.2.30:\n",
            "      Successfully uninstalled opencv-python-4.1.2.30\n",
            "Successfully installed opencv-python-3.3.1.11\n",
            "Cloning into 'monodepth2'...\n",
            "remote: Enumerating objects: 148, done.\u001b[K\n",
            "remote: Total 148 (delta 0), reused 0 (delta 0), pack-reused 148\u001b[K\n",
            "Receiving objects: 100% (148/148), 10.26 MiB | 37.38 MiB/s, done.\n",
            "Resolving deltas: 100% (71/71), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AK6si-eI1Owv"
      },
      "source": [
        "# ! python monodepth2/test_simple.py --image_path monodepth2/assets/test_image.jpg --model_name mono+stereo_640x192 --model_path /root/tmp/S_640x192/models/weights_19\r\n",
        "# /root/tmp/S_640x192/models/weights_9/encoder.pth"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsVkfx9I77aM",
        "outputId": "b157161c-5940-4137-f0eb-abf1f0c147b9"
      },
      "source": [
        "import torch\r\n",
        "! uname -a\r\n",
        "print(torch.cuda.is_available())\r\n",
        "print(torch.cuda.get_device_name())"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linux 28dd3f85ea1d 4.19.112+ #1 SMP Thu Jul 23 08:00:38 PDT 2020 x86_64 x86_64 x86_64 GNU/Linux\n",
            "True\n",
            "Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRh0z4t5QoiJ"
      },
      "source": [
        "# ! python monodepth2/train.py --model_name stereo_model  --frame_ids 0 --use_stereo --split eigen_full"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuIvPhbqecxe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6021e541-e644-4af5-f50f-fad9258a3803"
      },
      "source": [
        "! wget https://s3.eu-central-1.amazonaws.com/avg-kitti/raw_data/2011_09_28_calib.zip\r\n",
        "! wget https://s3.eu-central-1.amazonaws.com/avg-kitti/raw_data/2011_09_28_drive_0001/2011_09_28_drive_0001_sync.zip\r\n",
        "! wget https://s3.eu-central-1.amazonaws.com/avg-kitti/raw_data/2011_09_28_drive_0002/2011_09_28_drive_0002_sync.zip\r\n",
        "\r\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-18 04:00:17--  https://s3.eu-central-1.amazonaws.com/avg-kitti/raw_data/2011_09_28_calib.zip\n",
            "Resolving s3.eu-central-1.amazonaws.com (s3.eu-central-1.amazonaws.com)... 52.219.74.199\n",
            "Connecting to s3.eu-central-1.amazonaws.com (s3.eu-central-1.amazonaws.com)|52.219.74.199|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4073 (4.0K) [application/zip]\n",
            "Saving to: ‘2011_09_28_calib.zip’\n",
            "\n",
            "2011_09_28_calib.zi 100%[===================>]   3.98K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-12-18 04:00:18 (182 MB/s) - ‘2011_09_28_calib.zip’ saved [4073/4073]\n",
            "\n",
            "--2020-12-18 04:00:18--  https://s3.eu-central-1.amazonaws.com/avg-kitti/raw_data/2011_09_28_drive_0001/2011_09_28_drive_0001_sync.zip\n",
            "Resolving s3.eu-central-1.amazonaws.com (s3.eu-central-1.amazonaws.com)... 52.219.74.199\n",
            "Connecting to s3.eu-central-1.amazonaws.com (s3.eu-central-1.amazonaws.com)|52.219.74.199|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 424412944 (405M) [application/zip]\n",
            "Saving to: ‘2011_09_28_drive_0001_sync.zip’\n",
            "\n",
            "2011_09_28_drive_00 100%[===================>] 404.75M  2.78MB/s    in 2m 2s   \n",
            "\n",
            "2020-12-18 04:02:21 (3.32 MB/s) - ‘2011_09_28_drive_0001_sync.zip’ saved [424412944/424412944]\n",
            "\n",
            "--2020-12-18 04:02:21--  https://s3.eu-central-1.amazonaws.com/avg-kitti/raw_data/2011_09_28_drive_0002/2011_09_28_drive_0002_sync.zip\n",
            "Resolving s3.eu-central-1.amazonaws.com (s3.eu-central-1.amazonaws.com)... 52.219.72.139\n",
            "Connecting to s3.eu-central-1.amazonaws.com (s3.eu-central-1.amazonaws.com)|52.219.72.139|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1458258535 (1.4G) [application/zip]\n",
            "Saving to: ‘2011_09_28_drive_0002_sync.zip’\n",
            "\n",
            "2011_09_28_drive_00 100%[===================>]   1.36G  18.8MB/s    in 84s     \n",
            "\n",
            "2020-12-18 04:03:45 (16.6 MB/s) - ‘2011_09_28_drive_0002_sync.zip’ saved [1458258535/1458258535]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXHNpu6ySrUT"
      },
      "source": [
        "! mkdir kitti_data\r\n",
        "! unzip -q 2011_09_28_drive_0001_sync.zip -d kitti_data\r\n",
        "! rm -rf 2011_09_28_drive_0001_sync.zip\r\n",
        "! unzip -q 2011_09_28_drive_0002_sync.zip -d kitti_data\r\n",
        "! rm -rf 2011_09_28_drive_0002_sync.zip\r\n",
        "! unzip -q 2011_09_28_calib.zip -d kitti_data\r\n",
        "! rm -rf 2011_09_28_calib.zip"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5JE0YgXjVe-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b620a0e0-0350-4693-cf24-6e3099e914c1"
      },
      "source": [
        "! sudo apt update\r\n",
        "! sudo apt install imagemagick\r\n",
        "! sudo apt install parallel\r\n",
        "! find kitti_data/2011_09_28 -name '*.png' | parallel 'convert -quality 92 -sampling-factor 2x2,1x1,1x1 {.}.png {.}.jpg && rm {}'"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (91.189.88.142)] [Connecting to security.u\u001b[0m\u001b[33m\r0% [Connecting to archive.ubuntu.com (91.189.88.142)] [Connecting to security.u\u001b[0m\r                                                                               \rIgn:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (91.189.88.142)] [Connecting to security.u\u001b[0m\u001b[33m\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.142)\u001b[0m\r                                                                               \rIgn:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\u001b[33m\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.142)\u001b[0m\r                                                                               \rGet:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [697 B]\n",
            "\u001b[33m\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.142)\u001b[0m\r                                                                               \rHit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Get:7 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [40.7 kB]\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:9 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:11 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Ign:13 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages\n",
            "Get:13 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [506 kB]\n",
            "Get:14 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,372 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,244 kB]\n",
            "Get:18 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,699 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [237 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [1,816 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [266 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,136 kB]\n",
            "Get:23 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [15.3 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [53.8 kB]\n",
            "Get:25 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [870 kB]\n",
            "Get:26 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [46.5 kB]\n",
            "Fetched 11.6 MB in 4s (3,189 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "59 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  fonts-droid-fallback fonts-noto-mono ghostscript gsfonts\n",
            "  imagemagick-6-common imagemagick-6.q16 libcupsfilters1 libcupsimage2\n",
            "  libdjvulibre-text libdjvulibre21 libgs9 libgs9-common libijs-0.35\n",
            "  libjbig2dec0 liblqr-1-0 libmagickcore-6.q16-3 libmagickcore-6.q16-3-extra\n",
            "  libmagickwand-6.q16-3 libnetpbm10 libwmf0.2-7 netpbm poppler-data\n",
            "Suggested packages:\n",
            "  fonts-noto ghostscript-x imagemagick-doc autotrace cups-bsd | lpr | lprng\n",
            "  enscript gimp gnuplot grads hp2xx html2ps libwmf-bin mplayer povray radiance\n",
            "  sane-utils texlive-base-bin transfig ufraw-batch inkscape libjxr-tools\n",
            "  libwmf0.2-7-gtk poppler-utils fonts-japanese-mincho | fonts-ipafont-mincho\n",
            "  fonts-japanese-gothic | fonts-ipafont-gothic fonts-arphic-ukai\n",
            "  fonts-arphic-uming fonts-nanum\n",
            "The following NEW packages will be installed:\n",
            "  fonts-droid-fallback fonts-noto-mono ghostscript gsfonts imagemagick\n",
            "  imagemagick-6-common imagemagick-6.q16 libcupsfilters1 libcupsimage2\n",
            "  libdjvulibre-text libdjvulibre21 libgs9 libgs9-common libijs-0.35\n",
            "  libjbig2dec0 liblqr-1-0 libmagickcore-6.q16-3 libmagickcore-6.q16-3-extra\n",
            "  libmagickwand-6.q16-3 libnetpbm10 libwmf0.2-7 netpbm poppler-data\n",
            "0 upgraded, 23 newly installed, 0 to remove and 59 not upgraded.\n",
            "Need to get 18.4 MB of archives.\n",
            "After this operation, 66.3 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-droid-fallback all 1:6.0.1r16-1.1 [1,805 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 liblqr-1-0 amd64 0.4.2-2.1 [27.7 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 imagemagick-6-common all 8:6.9.7.4+dfsg-16ubuntu6.9 [60.0 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagickcore-6.q16-3 amd64 8:6.9.7.4+dfsg-16ubuntu6.9 [1,616 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagickwand-6.q16-3 amd64 8:6.9.7.4+dfsg-16ubuntu6.9 [293 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 poppler-data all 0.4.8-2 [1,479 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-noto-mono all 20171026-2 [75.5 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcupsimage2 amd64 2.2.7-1ubuntu2.8 [18.6 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 libijs-0.35 amd64 0.35-13 [15.5 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 libjbig2dec0 amd64 0.13-6 [55.9 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgs9-common all 9.26~dfsg+0-0ubuntu0.18.04.13 [5,092 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgs9 amd64 9.26~dfsg+0-0ubuntu0.18.04.13 [2,263 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 ghostscript amd64 9.26~dfsg+0-0ubuntu0.18.04.13 [51.0 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic/main amd64 gsfonts all 1:8.11+urwcyr1.0.7~pre44-4.4 [3,120 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 imagemagick-6.q16 amd64 8:6.9.7.4+dfsg-16ubuntu6.9 [423 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 imagemagick amd64 8:6.9.7.4+dfsg-16ubuntu6.9 [14.2 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcupsfilters1 amd64 1.20.2-0ubuntu3.1 [108 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libdjvulibre-text all 3.5.27.1-8ubuntu0.2 [49.3 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libdjvulibre21 amd64 3.5.27.1-8ubuntu0.2 [560 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic/main amd64 libwmf0.2-7 amd64 0.2.8.4-12 [150 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagickcore-6.q16-3-extra amd64 8:6.9.7.4+dfsg-16ubuntu6.9 [62.3 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic/main amd64 libnetpbm10 amd64 2:10.0-15.3build1 [58.0 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic/main amd64 netpbm amd64 2:10.0-15.3build1 [1,017 kB]\n",
            "Fetched 18.4 MB in 2s (7,818 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 23.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package fonts-droid-fallback.\n",
            "(Reading database ... 144865 files and directories currently installed.)\n",
            "Preparing to unpack .../00-fonts-droid-fallback_1%3a6.0.1r16-1.1_all.deb ...\n",
            "Unpacking fonts-droid-fallback (1:6.0.1r16-1.1) ...\n",
            "Selecting previously unselected package liblqr-1-0:amd64.\n",
            "Preparing to unpack .../01-liblqr-1-0_0.4.2-2.1_amd64.deb ...\n",
            "Unpacking liblqr-1-0:amd64 (0.4.2-2.1) ...\n",
            "Selecting previously unselected package imagemagick-6-common.\n",
            "Preparing to unpack .../02-imagemagick-6-common_8%3a6.9.7.4+dfsg-16ubuntu6.9_all.deb ...\n",
            "Unpacking imagemagick-6-common (8:6.9.7.4+dfsg-16ubuntu6.9) ...\n",
            "Selecting previously unselected package libmagickcore-6.q16-3:amd64.\n",
            "Preparing to unpack .../03-libmagickcore-6.q16-3_8%3a6.9.7.4+dfsg-16ubuntu6.9_amd64.deb ...\n",
            "Unpacking libmagickcore-6.q16-3:amd64 (8:6.9.7.4+dfsg-16ubuntu6.9) ...\n",
            "Selecting previously unselected package libmagickwand-6.q16-3:amd64.\n",
            "Preparing to unpack .../04-libmagickwand-6.q16-3_8%3a6.9.7.4+dfsg-16ubuntu6.9_amd64.deb ...\n",
            "Unpacking libmagickwand-6.q16-3:amd64 (8:6.9.7.4+dfsg-16ubuntu6.9) ...\n",
            "Selecting previously unselected package poppler-data.\n",
            "Preparing to unpack .../05-poppler-data_0.4.8-2_all.deb ...\n",
            "Unpacking poppler-data (0.4.8-2) ...\n",
            "Selecting previously unselected package fonts-noto-mono.\n",
            "Preparing to unpack .../06-fonts-noto-mono_20171026-2_all.deb ...\n",
            "Unpacking fonts-noto-mono (20171026-2) ...\n",
            "Selecting previously unselected package libcupsimage2:amd64.\n",
            "Preparing to unpack .../07-libcupsimage2_2.2.7-1ubuntu2.8_amd64.deb ...\n",
            "Unpacking libcupsimage2:amd64 (2.2.7-1ubuntu2.8) ...\n",
            "Selecting previously unselected package libijs-0.35:amd64.\n",
            "Preparing to unpack .../08-libijs-0.35_0.35-13_amd64.deb ...\n",
            "Unpacking libijs-0.35:amd64 (0.35-13) ...\n",
            "Selecting previously unselected package libjbig2dec0:amd64.\n",
            "Preparing to unpack .../09-libjbig2dec0_0.13-6_amd64.deb ...\n",
            "Unpacking libjbig2dec0:amd64 (0.13-6) ...\n",
            "Selecting previously unselected package libgs9-common.\n",
            "Preparing to unpack .../10-libgs9-common_9.26~dfsg+0-0ubuntu0.18.04.13_all.deb ...\n",
            "Unpacking libgs9-common (9.26~dfsg+0-0ubuntu0.18.04.13) ...\n",
            "Selecting previously unselected package libgs9:amd64.\n",
            "Preparing to unpack .../11-libgs9_9.26~dfsg+0-0ubuntu0.18.04.13_amd64.deb ...\n",
            "Unpacking libgs9:amd64 (9.26~dfsg+0-0ubuntu0.18.04.13) ...\n",
            "Selecting previously unselected package ghostscript.\n",
            "Preparing to unpack .../12-ghostscript_9.26~dfsg+0-0ubuntu0.18.04.13_amd64.deb ...\n",
            "Unpacking ghostscript (9.26~dfsg+0-0ubuntu0.18.04.13) ...\n",
            "Selecting previously unselected package gsfonts.\n",
            "Preparing to unpack .../13-gsfonts_1%3a8.11+urwcyr1.0.7~pre44-4.4_all.deb ...\n",
            "Unpacking gsfonts (1:8.11+urwcyr1.0.7~pre44-4.4) ...\n",
            "Selecting previously unselected package imagemagick-6.q16.\n",
            "Preparing to unpack .../14-imagemagick-6.q16_8%3a6.9.7.4+dfsg-16ubuntu6.9_amd64.deb ...\n",
            "Unpacking imagemagick-6.q16 (8:6.9.7.4+dfsg-16ubuntu6.9) ...\n",
            "Selecting previously unselected package imagemagick.\n",
            "Preparing to unpack .../15-imagemagick_8%3a6.9.7.4+dfsg-16ubuntu6.9_amd64.deb ...\n",
            "Unpacking imagemagick (8:6.9.7.4+dfsg-16ubuntu6.9) ...\n",
            "Selecting previously unselected package libcupsfilters1:amd64.\n",
            "Preparing to unpack .../16-libcupsfilters1_1.20.2-0ubuntu3.1_amd64.deb ...\n",
            "Unpacking libcupsfilters1:amd64 (1.20.2-0ubuntu3.1) ...\n",
            "Selecting previously unselected package libdjvulibre-text.\n",
            "Preparing to unpack .../17-libdjvulibre-text_3.5.27.1-8ubuntu0.2_all.deb ...\n",
            "Unpacking libdjvulibre-text (3.5.27.1-8ubuntu0.2) ...\n",
            "Selecting previously unselected package libdjvulibre21:amd64.\n",
            "Preparing to unpack .../18-libdjvulibre21_3.5.27.1-8ubuntu0.2_amd64.deb ...\n",
            "Unpacking libdjvulibre21:amd64 (3.5.27.1-8ubuntu0.2) ...\n",
            "Selecting previously unselected package libwmf0.2-7:amd64.\n",
            "Preparing to unpack .../19-libwmf0.2-7_0.2.8.4-12_amd64.deb ...\n",
            "Unpacking libwmf0.2-7:amd64 (0.2.8.4-12) ...\n",
            "Selecting previously unselected package libmagickcore-6.q16-3-extra:amd64.\n",
            "Preparing to unpack .../20-libmagickcore-6.q16-3-extra_8%3a6.9.7.4+dfsg-16ubuntu6.9_amd64.deb ...\n",
            "Unpacking libmagickcore-6.q16-3-extra:amd64 (8:6.9.7.4+dfsg-16ubuntu6.9) ...\n",
            "Selecting previously unselected package libnetpbm10.\n",
            "Preparing to unpack .../21-libnetpbm10_2%3a10.0-15.3build1_amd64.deb ...\n",
            "Unpacking libnetpbm10 (2:10.0-15.3build1) ...\n",
            "Selecting previously unselected package netpbm.\n",
            "Preparing to unpack .../22-netpbm_2%3a10.0-15.3build1_amd64.deb ...\n",
            "Unpacking netpbm (2:10.0-15.3build1) ...\n",
            "Setting up libgs9-common (9.26~dfsg+0-0ubuntu0.18.04.13) ...\n",
            "Setting up imagemagick-6-common (8:6.9.7.4+dfsg-16ubuntu6.9) ...\n",
            "Setting up fonts-droid-fallback (1:6.0.1r16-1.1) ...\n",
            "Setting up gsfonts (1:8.11+urwcyr1.0.7~pre44-4.4) ...\n",
            "Setting up poppler-data (0.4.8-2) ...\n",
            "Setting up libdjvulibre-text (3.5.27.1-8ubuntu0.2) ...\n",
            "Setting up libnetpbm10 (2:10.0-15.3build1) ...\n",
            "Setting up fonts-noto-mono (20171026-2) ...\n",
            "Setting up libcupsfilters1:amd64 (1.20.2-0ubuntu3.1) ...\n",
            "Setting up libcupsimage2:amd64 (2.2.7-1ubuntu2.8) ...\n",
            "Setting up liblqr-1-0:amd64 (0.4.2-2.1) ...\n",
            "Setting up libjbig2dec0:amd64 (0.13-6) ...\n",
            "Setting up libijs-0.35:amd64 (0.35-13) ...\n",
            "Setting up netpbm (2:10.0-15.3build1) ...\n",
            "Setting up libgs9:amd64 (9.26~dfsg+0-0ubuntu0.18.04.13) ...\n",
            "Setting up libwmf0.2-7:amd64 (0.2.8.4-12) ...\n",
            "Setting up libmagickcore-6.q16-3:amd64 (8:6.9.7.4+dfsg-16ubuntu6.9) ...\n",
            "Setting up libdjvulibre21:amd64 (3.5.27.1-8ubuntu0.2) ...\n",
            "Setting up ghostscript (9.26~dfsg+0-0ubuntu0.18.04.13) ...\n",
            "Setting up libmagickwand-6.q16-3:amd64 (8:6.9.7.4+dfsg-16ubuntu6.9) ...\n",
            "Setting up imagemagick-6.q16 (8:6.9.7.4+dfsg-16ubuntu6.9) ...\n",
            "update-alternatives: using /usr/bin/compare-im6.q16 to provide /usr/bin/compare (compare) in auto mode\n",
            "update-alternatives: using /usr/bin/compare-im6.q16 to provide /usr/bin/compare-im6 (compare-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/animate-im6.q16 to provide /usr/bin/animate (animate) in auto mode\n",
            "update-alternatives: using /usr/bin/animate-im6.q16 to provide /usr/bin/animate-im6 (animate-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/convert-im6.q16 to provide /usr/bin/convert (convert) in auto mode\n",
            "update-alternatives: using /usr/bin/convert-im6.q16 to provide /usr/bin/convert-im6 (convert-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/composite-im6.q16 to provide /usr/bin/composite (composite) in auto mode\n",
            "update-alternatives: using /usr/bin/composite-im6.q16 to provide /usr/bin/composite-im6 (composite-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/conjure-im6.q16 to provide /usr/bin/conjure (conjure) in auto mode\n",
            "update-alternatives: using /usr/bin/conjure-im6.q16 to provide /usr/bin/conjure-im6 (conjure-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/import-im6.q16 to provide /usr/bin/import (import) in auto mode\n",
            "update-alternatives: using /usr/bin/import-im6.q16 to provide /usr/bin/import-im6 (import-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/identify-im6.q16 to provide /usr/bin/identify (identify) in auto mode\n",
            "update-alternatives: using /usr/bin/identify-im6.q16 to provide /usr/bin/identify-im6 (identify-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/stream-im6.q16 to provide /usr/bin/stream (stream) in auto mode\n",
            "update-alternatives: using /usr/bin/stream-im6.q16 to provide /usr/bin/stream-im6 (stream-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/display-im6.q16 to provide /usr/bin/display (display) in auto mode\n",
            "update-alternatives: using /usr/bin/display-im6.q16 to provide /usr/bin/display-im6 (display-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/montage-im6.q16 to provide /usr/bin/montage (montage) in auto mode\n",
            "update-alternatives: using /usr/bin/montage-im6.q16 to provide /usr/bin/montage-im6 (montage-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/mogrify-im6.q16 to provide /usr/bin/mogrify (mogrify) in auto mode\n",
            "update-alternatives: using /usr/bin/mogrify-im6.q16 to provide /usr/bin/mogrify-im6 (mogrify-im6) in auto mode\n",
            "Setting up libmagickcore-6.q16-3-extra:amd64 (8:6.9.7.4+dfsg-16ubuntu6.9) ...\n",
            "Setting up imagemagick (8:6.9.7.4+dfsg-16ubuntu6.9) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  cron sysstat\n",
            "Suggested packages:\n",
            "  anacron logrotate checksecurity exim4 | postfix | mail-transport-agent isag\n",
            "The following NEW packages will be installed:\n",
            "  cron parallel sysstat\n",
            "0 upgraded, 3 newly installed, 0 to remove and 59 not upgraded.\n",
            "Need to get 624 kB of archives.\n",
            "After this operation, 2,470 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 cron amd64 3.0pl1-128.1ubuntu1 [68.8 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 sysstat amd64 11.6.1-1ubuntu0.1 [295 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 parallel all 20161222-1 [260 kB]\n",
            "Fetched 624 kB in 1s (510 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package cron.\n",
            "(Reading database ... 146823 files and directories currently installed.)\n",
            "Preparing to unpack .../cron_3.0pl1-128.1ubuntu1_amd64.deb ...\n",
            "Unpacking cron (3.0pl1-128.1ubuntu1) ...\n",
            "Selecting previously unselected package sysstat.\n",
            "Preparing to unpack .../sysstat_11.6.1-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking sysstat (11.6.1-1ubuntu0.1) ...\n",
            "Selecting previously unselected package parallel.\n",
            "Preparing to unpack .../parallel_20161222-1_all.deb ...\n",
            "Adding 'diversion of /usr/bin/parallel to /usr/bin/parallel.moreutils by parallel'\n",
            "Adding 'diversion of /usr/share/man/man1/parallel.1.gz to /usr/share/man/man1/parallel.moreutils.1.gz by parallel'\n",
            "Unpacking parallel (20161222-1) ...\n",
            "Setting up sysstat (11.6.1-1ubuntu0.1) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
            "debconf: falling back to frontend: Readline\n",
            "\n",
            "Creating config file /etc/default/sysstat with new version\n",
            "update-alternatives: using /usr/bin/sar.sysstat to provide /usr/bin/sar (sar) in auto mode\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/sysstat.service → /lib/systemd/system/sysstat.service.\n",
            "Setting up cron (3.0pl1-128.1ubuntu1) ...\n",
            "Adding group `crontab' (GID 109) ...\n",
            "Done.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/cron.service → /lib/systemd/system/cron.service.\n",
            "update-rc.d: warning: start and stop actions are no longer supported; falling back to defaults\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up parallel (20161222-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for systemd (237-3ubuntu10.43) ...\n",
            "Academic tradition requires you to cite works you base your article on.\n",
            "When using programs that use GNU Parallel to process data for publication\n",
            "please cite:\n",
            "\n",
            "  O. Tange (2011): GNU Parallel - The Command-Line Power Tool,\n",
            "  ;login: The USENIX Magazine, February 2011:42-47.\n",
            "\n",
            "This helps funding further development; AND IT WON'T COST YOU A CENT.\n",
            "If you pay 10000 EUR you should feel free to use GNU Parallel without citing.\n",
            "\n",
            "To silence this citation notice: run 'parallel --citation'.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5yRZNzAj_gx",
        "outputId": "2a5b85e8-7886-4c39-e12e-3b54c23f32e7"
      },
      "source": [
        "# ! python monodepth2/train.py --model_name S_640x192 --frame_ids 0 --use_stereo --pose_model_type separate_resnet --split eigen_full --data_path /content/kitti_data --num_epochs 10\r\n",
        "# /content/kitti_data/2011_09_26/2011_09_26_drive_0106_sync/image_02/data/0000000115.png"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2l-qT82snuo"
      },
      "source": [
        "# ! python monodepth2/export_gt_depth.py --data_path kitti_data --split eigen"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWvl5VeiuppM"
      },
      "source": [
        "# ! python monodepth2/evaluate_depth.py --data_path kitti_data --load_weights_folder /root/tmp/S_640x192/models/weights_19/ --eval_stereo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "c7mdtNn2xC6I"
      },
      "source": [
        "#@title Default title text\n",
        "### For Training\n",
        "import monodepth2.layers, monodepth2.utils, monodepth2.trainer\n",
        "import monodepth2.networks\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import timeit\n",
        "import PIL.Image as pil\n",
        "\n",
        "\n",
        "class MyTraining(object):\n",
        "    def __init__(self, batch):\n",
        "        self.batch = batch\n",
        "        self.h = 192\n",
        "        self.w = 640\n",
        "        if torch.cuda.is_available():\n",
        "            self.device = torch.device(\"cuda\")\n",
        "        else:\n",
        "            self.device = torch.device(\"cpu\")\n",
        "\n",
        "        # For listing which frames to check\n",
        "        # For simple stereo is only current (0) and estimated pair (s)\n",
        "        self.frames = [0, 's']\n",
        "\n",
        "        # For multi-scale estimation\n",
        "        self.loss_scales = [0, 1, 2, 3]\n",
        "\n",
        "        # Weighting for loss function\n",
        "        self.alpha = 0.85\n",
        "\n",
        "        # Define projections for pose estimation\n",
        "        self.depth_projection = {}\n",
        "        self.projection_3d = {}\n",
        "        for loss_scale in self.loss_scales:\n",
        "            h = int(self.h / (2 ** loss_scale))\n",
        "            w = int(self.w / (2 ** loss_scale))\n",
        "\n",
        "            self.depth_projection[loss_scale] = monodepth2.layers.BackprojectDepth(self.batch, h, w).to(self.device)\n",
        "            self.projection_3d[loss_scale] = monodepth2.layers.Project3D(self.batch, h, w).to(self.device)\n",
        "        \n",
        "        ## Declare Depth Network\n",
        "        self.depth_encoder_network = monodepth2.networks.ResnetEncoder(18, True).to(self.device)\n",
        "        self.depth_decoder_network = monodepth2.networks.DepthDecoder(self.depth_encoder_network.num_ch_enc, \n",
        "                                                [0, 1, 2, 3]).to(self.device) \n",
        "\n",
        "        ## Declare Pose Network\n",
        "        self.pose_encoder_network = monodepth2.networks.ResnetEncoder(18, True, num_input_images=2).to(self.device)\n",
        "        self.pose_decoder_network = monodepth2.networks.PoseDecoder(self.pose_encoder_network.num_ch_enc, \n",
        "                                                num_input_features=1, num_frames_to_predict_for=2).to(self.device)\n",
        "\n",
        "        self.models = {\"encoder\": self.depth_encoder_network, \"depth\": self.depth_decoder_network,\n",
        "                       \"pose_encoder\": self.pose_encoder_network, \"pose\": self.pose_decoder_network}\n",
        "\n",
        "        # Set up our excerpt of Kitti Dataset\n",
        "        training_files = monodepth2.utils.readlines(\"/content/monodepth2/splits/eigen_full/train_files.txt\")\n",
        "        validation_files = monodepth2.utils.readlines(\"/content/monodepth2/splits/eigen_full/val_files.txt\")\n",
        "\n",
        "        train_set = monodepth2.datasets.kitti_dataset.KITTIRAWDataset(\"/content/kitti_data\", training_files, self.h, self.w, self.frames, 4, is_train=True, img_ext='.jpg')\n",
        "        self.train_loader = DataLoader(train_set, self.batch, True, num_workers=6, pin_memory=True, drop_last=True)\n",
        "        val_set = monodepth2.datasets.kitti_dataset.KITTIRAWDataset(\"/content/kitti_data\", validation_files, self.h, self.w, self.frames, 4, is_train=False, img_ext='.jpg')\n",
        "        self.val_loader = DataLoader(val_set, self.batch, True, num_workers=6, pin_memory=True, drop_last=True)\n",
        "\n",
        "    def run_training_loop(self):\n",
        "        self.all_params = list(self.depth_encoder_network.parameters())\n",
        "        self.all_params += list(self.depth_decoder_network.parameters())\n",
        "        self.all_params += list(self.pose_encoder_network.parameters())\n",
        "        self.all_params += list(self.pose_decoder_network.parameters())\n",
        "\n",
        "        # Same learning rate configuration as https://arxiv.org/pdf/1806.01260.pdf\n",
        "        self.adam_optim = optim.Adam(self.all_params, 1e-4)\n",
        "        self.lr_sched = optim.lr_scheduler.StepLR(self.adam_optim, 15, 0.1)\n",
        "        self.ssim_loss_func = monodepth2.layers.SSIM().to(self.device)\n",
        "\n",
        "        self.epoch_count = 0\n",
        "        losses  = []\n",
        "\n",
        "        for self.epoch_count in range(2):\n",
        "            # Per Epoch\n",
        "            self.lr_sched.step()\n",
        "            self.depth_encoder_network.train()\n",
        "            self.depth_decoder_network.train()\n",
        "            self.pose_encoder_network.train()\n",
        "            self.pose_decoder_network.train()\n",
        "\n",
        "            for idx, inputs in enumerate(self.train_loader):\n",
        "                # Push to GPU\n",
        "                for key, ipt in inputs.items():\n",
        "                    inputs[key] = ipt.to(self.device)\n",
        "\n",
        "                # Per Batch Code\n",
        "                batch_start_time = timeit.default_timer()\n",
        "\n",
        "                feature_identifications = self.depth_encoder_network(inputs[\"color_aug\", 0, 0])\n",
        "                outputs = self.depth_decoder_network(feature_identifications)\n",
        "\n",
        "                self.estimate_stereo_predictions(inputs, outputs)\n",
        "                loss = self.batch_loss_func(inputs, outputs)\n",
        "\n",
        "                self.adam_optim.zero_grad()\n",
        "                loss[\"loss\"].backward()\n",
        "                losses.append(loss[\"loss\"].item())\n",
        "                self.adam_optim.step()\n",
        "\n",
        "                batch_duration = timeit.default_timer() - batch_start_time\n",
        "\n",
        "                # Do something with batch duration and losses\n",
        "\n",
        "    def estimate_stereo_predictions(self, inputs, outputs):\n",
        "        # Generate estimated stereo pair using the pose networks\n",
        "        for loss_scale in self.loss_scales:\n",
        "            estimated_disparity = outputs[(\"disp\", loss_scale)]\n",
        "            disp = F.interpolate(estimated_disparity, [self.h, self.w], mode=\"bilinear\", align_corners=False)\n",
        "            base = 0 # base scale\n",
        "\n",
        "            # Change names\n",
        "            scaled_disp = 0.001 + (10 - 0.001) * disp\n",
        "            depth = 1 / scaled_disp\n",
        "\n",
        "            outputs[(\"depth\", 0, loss_scale)] = depth\n",
        "\n",
        "            # Run for stereo pair\n",
        "            T = inputs[\"stereo_T\"]\n",
        "\n",
        "            camera_coords = self.depth_projection[base](depth, inputs[(\"inv_K\", base)])\n",
        "            pixel_coords = self.projection_3d[base](camera_coords, inputs[(\"K\", base)], T)\n",
        "\n",
        "            outputs[(\"sample\", 's', loss_scale)] = pixel_coords\n",
        "            outputs[(\"color\", 's', loss_scale)] = F.grid_sample(\n",
        "                inputs[(\"color\", 's', base)], outputs[(\"sample\", 's', loss_scale)], padding_mode=\"border\")\n",
        "                \n",
        "    def reprojection(self, prediction, target):\n",
        "        ssim_loss = self.ssim_loss_func(prediction, target).mean(1, True)\n",
        "        reproj_losses = self.alpha*ssim_loss + (1-self.alpha)*(torch.abs(target-prediction).mean(1, True))\n",
        "        return reproj_losses\n",
        "\n",
        "    def batch_loss_func(self, inputs, outputs):\n",
        "        batch_loss = {}\n",
        "        complete_losses = 0\n",
        "\n",
        "        for loss_scale in self.loss_scales:\n",
        "            current_loss = 0\n",
        "\n",
        "            base = 0\n",
        "\n",
        "            reproj_losses = []\n",
        "\n",
        "            reproj_losses.append(self.reprojection(outputs[(\"color\", 's', loss_scale)], inputs[(\"color\", 0, base)]))\n",
        "            reproj_losses = torch.cat(reproj_losses, 1)\n",
        "\n",
        "            identity_loss = []\n",
        "            identity_loss.append(self.reprojection(inputs[(\"color\", 's', base)], inputs[(\"color\", 0, base)]))\n",
        "            identity_loss = torch.cat(identity_loss, 1)\n",
        "\n",
        "\n",
        "            # Add some minor noise to ensure no repeated values\n",
        "            identity_loss += torch.rand(identity_loss.shape).cuda() * 0.00001\n",
        "            total = torch.cat((identity_loss, reproj_losses), dim=1)\n",
        "            val, idxs = torch.min(total, dim=1)\n",
        "\n",
        "            # UNDERSTAND THIS LINE MORE\n",
        "            outputs[\"identity_selection/{}\".format(loss_scale)] = (idxs > identity_loss.shape[1] - 1).float()\n",
        "\n",
        "            current_loss += val.mean()\n",
        "\n",
        "            mean_disp = outputs[(\"disp\", loss_scale)].mean(2, True).mean(3, True)\n",
        "            norm_disp = outputs[(\"disp\", loss_scale)] / (mean_disp + 1e-7)\n",
        "            smooth_loss = monodepth2.layers.get_smooth_loss(norm_disp, inputs[(\"color\", 0, loss_scale)])\n",
        "\n",
        "            current_loss += 1e-3 * smooth_loss / (2 ** loss_scale)\n",
        "            complete_losses += current_loss\n",
        "            batch_loss[\"loss/{}\".format(loss_scale)] = current_loss\n",
        "\n",
        "        complete_losses /= len(self.loss_scales)\n",
        "        batch_loss[\"loss\"] = complete_losses\n",
        "        return batch_loss\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgYHittywMt5"
      },
      "source": [
        "\r\n",
        "import os\r\n",
        "import torchvision.models as models\r\n",
        "\r\n",
        "def save_model(train):\r\n",
        "    \"\"\"Save model weights to disk\r\n",
        "    \"\"\"\r\n",
        "    save_folder = os.path.join(\"/content/test_model/\")\r\n",
        "    if not os.path.exists(save_folder):\r\n",
        "        os.makedirs(save_folder)\r\n",
        "\r\n",
        "    for model_name, model in train.models.items():\r\n",
        "        save_path = os.path.join(save_folder, \"{}.pth\".format(model_name))\r\n",
        "        to_save = model.state_dict()\r\n",
        "        if 'encoder' in model_name:\r\n",
        "            # save the sizes - these are needed at prediction time\r\n",
        "            to_save['height'] = train.h\r\n",
        "            to_save['width'] = train.w\r\n",
        "            to_save['use_stereo'] = True\r\n",
        "        torch.save(to_save, save_path)\r\n",
        "\r\n",
        "    save_path = os.path.join(save_folder, \"{}.pth\".format(\"adam\"))\r\n",
        "    torch.save(train.adam_optim.state_dict(), save_path)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ow5DP4v9zQEH",
        "outputId": "141b8a5f-68dd-40b9-edf8-2e19aeb299c6"
      },
      "source": [
        "train = MyTraining(6)\r\n",
        "train.run_training_loop()\r\n",
        "save_model(train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3385: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
            "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVMqZmbOPPeE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bba1d63-978b-401c-8120-c74e4e8a7a07"
      },
      "source": [
        "! python monodepth2/test_simple.py --image_path monodepth2/assets/test_image.jpg --model_name mono+stereo_640x192 --model_path /content/test_model/\r\n",
        "\r\n",
        "# import PIL.Image as pil\r\n",
        "# import matplotlib.pyplot as plt\r\n",
        "# from torchvision import transforms\r\n",
        "\r\n",
        "# image_path = \"monodepth2/assets/test_image.jpg\"\r\n",
        "\r\n",
        "# input_image = pil.open(image_path).convert('RGB')\r\n",
        "# original_width, original_height = input_image.size\r\n",
        "\r\n",
        "# feed_height = train.h\r\n",
        "# feed_width = train.w\r\n",
        "# input_image_resized = input_image.resize((feed_width, feed_height), pil.LANCZOS)\r\n",
        "\r\n",
        "# input_image_pytorch = transforms.ToTensor()(input_image_resized).unsqueeze(0)\r\n",
        "\r\n",
        "# with torch.no_grad():\r\n",
        "#     features = train.depth_decoder_network(input_image_pytorch)\r\n",
        "#     outputs = train.depth_decoder_network(features)\r\n",
        "\r\n",
        "# disp = outputs[(\"disp\", 0)]\r\n",
        "\r\n",
        "# disp_resized = torch.nn.functional.interpolate(disp,\r\n",
        "#     (original_height, original_width), mode=\"bilinear\", align_corners=False)\r\n",
        "\r\n",
        "# # Saving colormapped depth image\r\n",
        "# disp_resized_np = disp_resized.squeeze().cpu().numpy()\r\n",
        "# vmax = np.percentile(disp_resized_np, 95)\r\n",
        "\r\n",
        "# plt.figure(figsize=(10, 10))\r\n",
        "# plt.subplot(211)\r\n",
        "# plt.imshow(input_image)\r\n",
        "# plt.title(\"Input\", fontsize=22)\r\n",
        "# plt.axis('off')\r\n",
        "\r\n",
        "# plt.subplot(212)\r\n",
        "# plt.imshow(disp_resized_np, cmap='magma', vmax=vmax)\r\n",
        "# plt.title(\"Disparity prediction\", fontsize=22)\r\n",
        "# plt.axis('off')\r\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-> Loading model from  /content/test_model/\n",
            "   Loading pretrained encoder\n",
            "   Loading pretrained decoder\n",
            "-> Predicting on 1 test images\n",
            "   Processed 1 of 1 images - saved prediction to monodepth2/assets/test_image_disp.jpeg\n",
            "-> Done!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}